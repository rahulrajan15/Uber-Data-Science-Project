# Uber Data Science GCP Project

# Introduction
The goal of this project is to perform data analytics on Uber data using various tools and technologies, 
including GCP Storage, Python, Compute Instance, Mage Data Pipeline Tool, BigQuery and Looker Studio.

# Project Summary
This Project is a cutting-edge initiative that leverages the capabilities of Google Cloud Platform (GCP) to analyze and extract valuable insights from Uber's extensive data resources. By employing advanced data analytics techniques, machine learning algorithms, and data visualization tools on GCP, the project aims to optimize business operations, improve service efficiency, and enhance the overall customer experience. Through this data-driven approach, Uber can make informed decisions, identify growth opportunities, and stay at the forefront of the transportation industry.

# Architecture 
![process_architecture](https://github.com/rahulrajan15/Uber-Data-Science-Project/assets/113009011/65fe2e07-9226-4dc6-9e80-eab9f22015f4)

# Technology Used
Programming Language - Python
Google Cloud Platform

1) Google Storage
2) Compute Instance
3) BigQuery
4) Looker Studio
5) Modern Data Pipeine Tool - https://www.mage.ai/
   Contibute to this open source project - https://github.com/mage-ai/mage-ai

# Dataset Used
TLC Trip Record Data Yellow and green taxi trip records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts.
Here is the dataset used in the video - https://storage.googleapis.com/uber-datasets/uber_data.csv

More info about dataset can be found here:
1) Website - https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
2) Data Dictionary - https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf

![data_model_diagram](https://github.com/rahulrajan15/Uber-Data-Science-Project/assets/113009011/678b9cc1-0664-4df1-b8ae-cdb8c1b3ff57)

# Key Points from Project
1) Utilized GCP storage and configuration to efficiently store the dataset in Google Cloud Storage for the project.
2) Implemented new VM instances for the "MAGE Data Pipeline Tool" and executed the ETL process seamlessly.
3) Conducted in-depth data analysis post ETL, generating queries for BigQuery Analysis, and assembling the final table for comprehensive big data analysis.
4) Facilitated data visualization by loading results from BigQuery into Looker Studio, enabling intuitive data representation.
5) Crafted key performance indicators (KPIs), charts, and scoreboards for a client-focused dashboard, effectively presenting business insights.

# Screenshots 
1) Uber Dashboard
![1](https://github.com/rahulrajan15/Uber-Data-Science-Project/assets/113009011/cede310a-b144-49a5-9f92-ca996f179bba)

![2](https://github.com/rahulrajan15/Uber-Data-Science-Project/assets/113009011/226c1e73-244f-40b8-b377-ea4853403388)


2) MAGE Data Pipeline Process
![3](https://github.com/rahulrajan15/Uber-Data-Science-Project/assets/113009011/aecd4016-5ffe-41df-93c2-6720ec804886)


----- Thank You ------

